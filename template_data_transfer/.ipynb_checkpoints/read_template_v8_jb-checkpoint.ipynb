{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code to Extract Data From Template and Transfer to PostGRE SQL\n",
    "#### Authors : Aaron Liu, Rahul Venkatesh, Jessica Bonsu, Myeongyeon Lee \n",
    "##### Date Edited : 06-07-2023"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
=======
   "execution_count": 83,
   "id": "d48be935",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"127.0.0.1\", port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\GitHub\\ofet-db\\1.create_ofetdb\\create_ofetdb_tables.py:17\u001b[0m\n\u001b[0;32m      7\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mofetdb_testenv_RV\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5432\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# %% Create Tables for EXPERIMENT_INFO\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m conn \u001b[38;5;241m=\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnnection Successful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m cur \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"127.0.0.1\", port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n"
     ]
    }
   ],
   "source": [
    "%run ..\\1.create_ofetdb\\create_ofetdb_tables - Copy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18bc8b22",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run .../1.create_ofetdb/create_ofetdb_tables_jb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## Required Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "\n",
    "import os\n",
    "from psycopg2.extras import Json\n",
    "from psycopg2.extensions import AsIs\n",
    "import functools\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "# import bibtexparser\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 38,
   "id": "db41ddb1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Functions To Extract Information from Template\n",
    "\n",
    "# Function to remove rows that have no value (NaN) in the second column\n",
    "def remove_emptyrows(df):\n",
    "    nan_mask = ~df.iloc[:,1].isna() \n",
    "    return df[nan_mask]\n",
    "\n",
    "# Function to convert a sheet into dictionary data type\n",
    "def read_sheet(filepath, sheet_name, ordering=False, usecols=\"A,B,D\", meas=False):\n",
    "\n",
    "    ## NOTE: ADD AN ARGUMENT TO DECIDE WHETHER OR NOT TO BRACKET THE SHEET\n",
    "    ## NOTE : The argument \"ordering\" is used for sheets like solution processing or substrate pretreatmant where the order of the processing step matters\n",
    "    ## NOTE : The argument \"usecols\" is to store information from particular columns in the excel sheet\n",
    "    ## NOTE : The argument \"meas\" is used to \n",
    "    \n",
    "    ## Read Sheet Information\n",
    "    df = pd.read_excel(\n",
    "        filepath,\n",
    "        sheet_name=sheet_name,\n",
    "        usecols=usecols\n",
    "    )\n",
    "    \n",
    "    # Call Function To Remove empty rows\n",
    "    df_ = remove_emptyrows(df)\n",
    "    \n",
    "    # Create an empty dictionary\n",
    "    sheet_dict = dict()\n",
    "\n",
    "    # To account for sheets where processing order is important\n",
    "    if ordering==True:\n",
    "        df_list = split_df(df_) #calls function split_df\n",
    "        for i, df in enumerate(df_list):\n",
    "            sheet_dict[i] = table_to_dict(df) #adds each table to the dictionary\n",
    "    else:\n",
    "        sheet_dict = table_to_dict(df_)\n",
    "    \n",
    "    return sheet_dict #returns a dataframe\n",
    "\n",
    "def split_df(df_):\n",
    "    #For sheets where processing order is important, this function finds tables with '#' in the name of the first column title and turns it into a df\n",
    "    \n",
    "    split_idx_mask = df_.iloc[:,0].str.contains('#') #Find the object splits\n",
    "    w = df_[split_idx_mask].index.values\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for i in range(len(w)-1):\n",
    "        next_df = df_.loc[w[i]+1:w[i+1]-1,:]\n",
    "        df_list.append(next_df)    \n",
    "    \n",
    "    return df_list\n",
    "\n",
    "def table_to_dict(df_):\n",
    "    \n",
    "    main_mask = pd.isna(df_.JSON) # it flags rows that dont have a value for JSON column\n",
    "    step_dict = dict(df_[main_mask].iloc[:,:2].values) # Stores rows that have \"NaN\" for JSON column in df_ as dict\n",
    "\n",
    "    \n",
    "    \n",
    "    for json_field in pd.unique(df_.JSON): #read through unique JSON types (e.g. NaN, meta or data)\n",
    "\n",
    "        if pd.isna(json_field): #ignore fields with JSON type as NaN\n",
    "            continue\n",
    "            \n",
    "        # dictionary to store information with JSON type \"data\"\n",
    "        elif json_field=='data':\n",
    "            data_mask = df_.JSON=='data'\n",
    "            \n",
    "            # lump key:value pairs into a second nested data dict\n",
    "            step_dict['data'] = dict()\n",
    "            \n",
    "            for i, s in df_[data_mask].iterrows():\n",
    "                step_dict['data'][s[s.index[0]]] = s['value':'error_type'].dropna().to_dict()\n",
    "        else:\n",
    "            json_mask = df_.JSON==json_field\n",
    "            step_dict[json_field] = dict(df_[json_mask].iloc[:,:2].values) # creates a new key for JSON types like meta and params and adds its corresponding values to it \n",
    "\n",
    "    return step_dict\n",
    "\n",
    "# f = pd.ExcelFile(fpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Extracting Data From Sheets in Template"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 36,
=======
   "execution_count": 61,
   "id": "6c9147c1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data From Sheets in Template\n",
    "\n",
    "#fpath = r'..\\db_feed\\v6_example_1_real.xlsx' #Add path for template file\n",
    "fpath = r'..\\db_feed\\v6_example.xlsx' #Add path for template file\n",
    "\n",
    "#Storing each sheet in the template file as a dictionary\n",
    "exp_info = read_sheet(fpath, 'Data Origin')\n",
    "solution_makeup = read_sheet(fpath, 'Solution Makeup', ordering=True)\n",
    "solution_processing = read_sheet(fpath, 'Solution Treatment', ordering=True)\n",
    "device_fab = read_sheet(fpath, 'Device Fabrication')\n",
    "substrate_pretreat = read_sheet(fpath, 'Substrate Pretreat', ordering=True)\n",
    "coating_process = read_sheet(fpath, 'Coating Process')\n",
    "post_process = read_sheet(fpath, 'Post-Processing', ordering=True)\n",
    "device_meas = read_sheet(fpath, 'Device Measurement', usecols=\"A:G\", ordering=True)\n",
    "other_meas = read_sheet(fpath, 'Other Measurements', usecols=\"A:G\", ordering=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 24,
=======
   "execution_count": 40,
   "id": "1328109a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "{0: {'treatment_type': 'mixing',\n",
       "  'process_step': 1,\n",
       "  'params': {'mixing_speed': 250, 'temperature': 60, 'time': 1}},\n",
       " 1: {'treatment_type': 'poor_solvent',\n",
       "  'process_step': 2,\n",
       "  'params': {'environment': 'air',\n",
       "   'iupac_name': 'acetone',\n",
       "   'pubchem_cid': 180,\n",
       "   'vol_frac_added': 0.05}}}"
      ]
     },
     "execution_count": 24,
=======
       "{0: {'treatment_type': 'sam',\n",
       "  'process_step': 1,\n",
       "  'params': {'sam_name': 'OTS-18',\n",
       "   'iupac_name': 'octadecyltrichlorosilane',\n",
       "   'pubchem_cid': 8157}}}"
      ]
     },
     "execution_count": 40,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use this code block to check how each sheet has been converted to a dictionary\n",
<<<<<<< Updated upstream
    "solution_processing"
=======
    "substrate_pretreat"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferring Information From Template To PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 41,
   "id": "49c23b3c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres python\n",
    "from psycopg2.extras import Json \n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def nan_to_null(f,\n",
    "        _NULL=AsIs('NULL'),\n",
    "        _Float=pg.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "param_dict = {\n",
    "    \"host\"      : \"127.0.0.1\",\n",
    "    \"database\"  : \"ofetdb_testenv\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = connect(param_dict)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "        # Fetch result\n",
    "        fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return fetched #return query result"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
=======
   "execution_count": 42,
   "id": "676e5391",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import Json\n",
    "\n",
    "def convert_entry(entry_dict):\n",
    "    \n",
    "    #This function reads a dictionary and extracts the column names and values from it\n",
    "    \n",
    "    pg_entry = entry_dict\n",
    "    for key in pg_entry.keys():\n",
    "        if type(pg_entry[key])==dict:\n",
    "            pg_entry[key]=Json(pg_entry[key])\n",
    "    columns = pg_entry.keys()\n",
    "    values = [pg_entry[column] for column in columns]\n",
    "    \n",
    "    return pg_entry, columns, values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Doubt 1 : \n",
    "\n",
    "I made a new database. we were not able to add any new records to the old database\n",
    "\n",
    "- might have to manually fix this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Checking and Storing Experiment Information"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
=======
   "execution_count": 43,
   "id": "892dc181",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "exp_pg_entry, exp_columns, exp_values = convert_entry(exp_info)\n",
    "\n",
    "#print(type(pg_entry))\n",
    "#print(type(columns))\n",
    "#print(columns)\n",
    "#print(type(values))\n",
    "#print(values)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
=======
   "execution_count": 44,
   "id": "aad022e8",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 17,
=======
     "execution_count": 44,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO experiment_info (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (citation_type, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING exp_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(exp_columns)), tuple(exp_values), AsIs(','.join(exp_columns)), tuple(exp_values))\n",
    "\n",
    "\n",
    "\n",
    "exp_id = pg_query(sql, tup)\n",
    "exp_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
<<<<<<< Updated upstream
=======
   "id": "8f44aff1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Dont forget to assign the exp_id to sample table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Checking and Storing Solution Information (Polymer, Solvent, Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
<<<<<<< Updated upstream
=======
   "id": "bf2333df",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<psycopg2._json.Json object at 0x000001A4603365C0>, <psycopg2._json.Json object at 0x000001A460337910>, <psycopg2._json.Json object at 0x000001A4603346A0>, <psycopg2._json.Json object at 0x000001A460337550>]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "pg_entry_solution_makeup, columns_solution_makeup, values_solution_makeup = convert_entry(solution_makeup)\n",
    "\n",
    "print(values_solution_makeup)\n",
    "print(type(values_solution_makeup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
<<<<<<< Updated upstream
=======
   "id": "f9d89a44",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_type': 'solution', 'concentration': 4}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solution data\n",
    "\n",
    "solution_data = values_solution_makeup[0].adapted\n",
    "\n",
    "solution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
<<<<<<< Updated upstream
=======
   "id": "d085ac8c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'solvent',\n",
       "  'iupac_name': '1,2-dichlorobenzene',\n",
       "  'pubchem_cid': 7239,\n",
       "  'vol_frac': 1}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solvent data - accounting for multiple solvents\n",
    "solvent_data_filtered = [json_obj for json_obj in values_solution_makeup if json_obj.adapted.get(\"entity_type\") == \"solvent\"]\n",
    "\n",
    "# Convert psycopg2._json.Json objects to JSON strings\n",
    "solvent_data = [json_obj.adapted for json_obj in solvent_data_filtered]\n",
    "\n",
    "solvent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
<<<<<<< Updated upstream
=======
   "id": "7b6bf440",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'polymer',\n",
       "  'common_name': 'DPP-DTT',\n",
       "  'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "  'mn': 55,\n",
       "  'mw': 199,\n",
       "  'dispersity': 3.62,\n",
       "  'wt_frac': 0.6,\n",
       "  'meta': {'supplier': 'Osilla', 'batch_number': 'M0311A2'}},\n",
       " {'entity_type': 'polymer',\n",
       "  'common_name': 'PS',\n",
       "  'iupac_name': 'poly(styrene)',\n",
       "  'mn': 2.18,\n",
       "  'mw': 2.2,\n",
       "  'dispersity': 1.01,\n",
       "  'wt_frac': 0.4,\n",
       "  'meta': {'supplier': 'Sigma', 'batch_number': 'S1234'}}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Polymer data - accounting for multiple polymers\n",
    "polymer_data_filtered = [json_obj for json_obj in values_solution_makeup if json_obj.adapted.get(\"entity_type\") == \"polymer\"]\n",
    "\n",
    "# Convert psycopg2._json.Json objects to JSON strings\n",
    "polymer_data = [json_obj.adapted for json_obj in polymer_data_filtered]\n",
    "\n",
    "polymer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
<<<<<<< Updated upstream
=======
   "id": "662d8fd3",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'solution', 'concentration': 4},\n",
       " [{'entity_type': 'solvent',\n",
       "   'iupac_name': '1,2-dichlorobenzene',\n",
       "   'pubchem_cid': 7239,\n",
       "   'vol_frac': 1}],\n",
       " [{'entity_type': 'polymer',\n",
       "   'common_name': 'DPP-DTT',\n",
       "   'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "   'mn': 55,\n",
       "   'mw': 199,\n",
       "   'dispersity': 3.62,\n",
       "   'wt_frac': 0.6,\n",
       "   'meta': {'supplier': 'Osilla', 'batch_number': 'M0311A2'}},\n",
       "  {'entity_type': 'polymer',\n",
       "   'common_name': 'PS',\n",
       "   'iupac_name': 'poly(styrene)',\n",
       "   'mn': 2.18,\n",
       "   'mw': 2.2,\n",
       "   'dispersity': 1.01,\n",
       "   'wt_frac': 0.4,\n",
       "   'meta': {'supplier': 'Sigma', 'batch_number': 'S1234'}}]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solution Makeup data\n",
    "\n",
    "solution_makeup_data = []\n",
    "solution_makeup_data.append(solution_data)\n",
    "solution_makeup_data.append(solvent_data)\n",
    "solution_makeup_data.append(polymer_data)\n",
    "solution_makeup_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inserting into POLYMER, SOLVENT, SOLUTION, SOLUTION_MAKEUP_POLYMER, SOLUTION_MAKEUP_SOLVENT tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should handle multiple solvents each with a vol_frac and multiple polymers each with a wt_frac, and it will check for the existence of a unique combination of concentration, polymer IDs, solvent IDs, wt_fracs, and vol_fracs. If the combination exists, it will assign the existing solution_id in all tables; otherwise, it will create a new solution_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
<<<<<<< Updated upstream
=======
   "id": "0c7ebe59",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: there is no unique or exclusion constraint matching the ON CONFLICT specification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Extract solution information\n",
    "solution_data = solution_makeup_data[0]\n",
    "concentration = solution_data['concentration']\n",
    "\n",
    "# Extract solvent information\n",
    "solvent_data = solution_makeup_data[1]\n",
    "solvent_ids = []\n",
    "vol_fracs = []\n",
    "for solvent in solvent_data:\n",
    "    pubchem_cid = solvent['pubchem_cid']\n",
    "    iupac_name = solvent['iupac_name']\n",
    "    vol_frac = solvent['vol_frac']\n",
    "    solvent_ids.append((pubchem_cid, iupac_name))\n",
    "    vol_fracs.append(vol_frac)\n",
    "\n",
    "# Extract polymer information\n",
    "polymer_data = solution_makeup_data[2]\n",
    "polymer_ids = []\n",
    "wt_fracs = []\n",
    "for polymer in polymer_data:\n",
    "    common_name = polymer['common_name']\n",
    "    iupac_name = polymer['iupac_name']\n",
    "    mn = polymer['mn']\n",
    "    mw = polymer['mw']\n",
    "    dispersity = polymer['dispersity']\n",
    "    wt_frac = polymer['wt_frac']\n",
    "    meta = json.dumps(polymer['meta'])\n",
    "    polymer_ids.append((common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "    wt_fracs.append(wt_frac)\n",
    "\n",
    "# Start transaction\n",
    "with connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        try:\n",
    "            # Check if the unique combination exists\n",
    "            select_solution_id_sql = '''\n",
    "                SELECT sm.solution_id\n",
    "                FROM SOLUTION_MAKEUP_SOLVENT sms\n",
    "                JOIN SOLUTION_MAKEUP_POLYMER smp ON sms.solution_id = smp.solution_id\n",
    "                JOIN SOLVENT s ON sms.solvent_id = s.pubchem_cid\n",
    "                JOIN POLYMER p ON smp.polymer_id = p.polymer_id\n",
    "                JOIN SOLUTION sm ON sms.solution_id = sm.solution_id\n",
    "                WHERE sm.concentration = %s\n",
    "                AND (s.pubchem_cid, s.iupac_name) IN %s\n",
    "                AND (p.common_name, p.iupac_name, p.mn, p.mw, p.dispersity, p.meta) IN %s\n",
    "                GROUP BY sm.solution_id\n",
    "                HAVING COUNT(DISTINCT smp.polymer_id) = %s\n",
    "                AND COUNT(DISTINCT sms.solvent_id) = %s\n",
    "                AND ARRAY_AGG(sms.vol_frac) = %s::double precision[]\n",
    "                AND ARRAY_AGG(smp.wt_frac) = %s::double precision[]\n",
    "            '''\n",
    "\n",
    "            cursor.execute(select_solution_id_sql, (concentration, tuple(solvent_ids), tuple(polymer_ids), len(polymer_ids), len(solvent_ids), vol_fracs, wt_fracs))\n",
    "            existing_solution = cursor.fetchone()\n",
    "            if existing_solution:\n",
    "                solution_id = existing_solution[0]\n",
    "            else:\n",
    "                # Insert into SOLUTION table\n",
    "                insert_solution_sql = '''\n",
    "                    INSERT INTO SOLUTION (concentration)\n",
    "                    VALUES (%s)\n",
    "                    RETURNING solution_id\n",
    "                '''\n",
    "                cursor.execute(insert_solution_sql, (concentration,))\n",
    "                solution_id = cursor.fetchone()[0]\n",
    "\n",
    "            for solvent_id, vol_frac in zip(solvent_ids, vol_fracs):\n",
    "                pubchem_cid, iupac_name = solvent_id\n",
    "\n",
    "                # Insert into SOLVENT table\n",
    "                insert_solvent_sql = '''\n",
    "                    INSERT INTO SOLVENT (pubchem_cid, iupac_name)\n",
    "                    VALUES (%s, %s)\n",
    "                    ON CONFLICT (iupac_name) DO UPDATE\n",
    "                    SET (pubchem_cid, iupac_name) = (%s, %s)\n",
    "                    RETURNING pubchem_cid\n",
    "                '''\n",
    "                cursor.execute(insert_solvent_sql, (pubchem_cid, iupac_name, pubchem_cid, iupac_name))\n",
    "                solvent_id = cursor.fetchone()[0]\n",
    "\n",
    "                # Insert into SOLUTION_MAKEUP_SOLVENT table\n",
    "                insert_solution_makeup_solvent_sql = '''\n",
    "                    INSERT INTO SOLUTION_MAKEUP_SOLVENT (solution_id, solvent_id, vol_frac)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                '''\n",
    "                cursor.execute(insert_solution_makeup_solvent_sql, (solution_id, solvent_id, vol_frac))\n",
    "\n",
    "            for polymer_id, wt_frac in zip(polymer_ids, wt_fracs):\n",
    "                common_name, iupac_name, mn, mw, dispersity, meta = polymer_id\n",
    "\n",
    "                # Check if the polymer exists\n",
    "                select_polymer_id_sql = '''\n",
    "                    SELECT polymer_id\n",
    "                    FROM POLYMER\n",
    "                    WHERE common_name = %s\n",
    "                    AND iupac_name = %s\n",
    "                    AND mn = %s\n",
    "                    AND mw = %s\n",
    "                    AND dispersity = %s\n",
    "                    AND meta = %s::jsonb\n",
    "                '''\n",
    "                cursor.execute(select_polymer_id_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                existing_polymer = cursor.fetchone()\n",
    "\n",
    "                if existing_polymer:\n",
    "                    polymer_id = existing_polymer[0]\n",
    "                else:\n",
    "                    # Insert into POLYMER table\n",
    "                    insert_polymer_sql = '''\n",
    "                        INSERT INTO POLYMER (common_name, iupac_name, mn, mw, dispersity, meta)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s::jsonb)\n",
    "                        RETURNING polymer_id\n",
    "                    '''\n",
    "                    cursor.execute(insert_polymer_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                    polymer_id = cursor.fetchone()[0]\n",
    "\n",
    "                # Insert into SOLUTION_MAKEUP_POLYMER table\n",
    "                insert_solution_makeup_polymer_sql = '''\n",
    "                    INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                '''\n",
    "                cursor.execute(insert_solution_makeup_polymer_sql, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "            print(\"Solution makeup saved successfully!\")\n",
    "        except Exception as e:\n",
    "            connection.rollback()\n",
    "            print(\"An error occurred:\", str(e))\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Checking and Storing Device Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
<<<<<<< Updated upstream
=======
   "id": "c797b4eb",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['params', 'meta'])\n",
      "<class 'list'>\n",
      "[<psycopg2._json.Json object at 0x000001A461BA8E80>, <psycopg2._json.Json object at 0x000001A461A1B970>]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "device_fab_pg_entry, device_fab_columns, device_fab_values = convert_entry(device_fab)\n",
    "\n",
    "#print(type(device_fab_pg_entry))\n",
    "#print(type(device_fab_columns))\n",
    "print(device_fab_columns)\n",
    "print(type(device_fab_values))\n",
    "print(device_fab_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
<<<<<<< Updated upstream
=======
   "id": "6bbe3e38",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO DEVICE_FABRICATION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING device_fab_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(device_fab_columns)), tuple(device_fab_values), AsIs(','.join(device_fab_columns)), tuple(device_fab_values))\n",
    "\n",
    "\n",
    "\n",
    "device_fab_id = pg_query(sql, tup)\n",
    "device_fab_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking and Storing Film Deposition Information "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 26,
=======
   "execution_count": 54,
   "id": "297a0f47",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['deposition_type', 'params'])\n",
      "<class 'list'>\n",
<<<<<<< Updated upstream
      "['spin', <psycopg2._json.Json object at 0x000001DF55713DA0>]\n"
=======
      "['spin', <psycopg2._json.Json object at 0x000001A461BAA290>]\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "coating_process_pg_entry, coating_process_columns, coating_process_values = convert_entry(coating_process)\n",
    "\n",
    "#print(type(coating_process_pg_entry))\n",
    "#print(type(coating_process_columns))\n",
    "print(coating_process_columns)\n",
    "print(type(coating_process_values))\n",
    "print(coating_process_values)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 27,
=======
   "execution_count": 55,
   "id": "8f5c4191",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
<<<<<<< Updated upstream
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
=======
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fetched' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    INSERT INTO FILM_DEPOSITION (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    VALUES \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    \u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      9\u001b[0m tup \u001b[38;5;241m=\u001b[39m (AsIs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(coating_process_columns)), \u001b[38;5;28mtuple\u001b[39m(coating_process_values), AsIs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(coating_process_columns)), \u001b[38;5;28mtuple\u001b[39m(coating_process_values))\n\u001b[1;32m---> 13\u001b[0m film_deposition_id \u001b[38;5;241m=\u001b[39m \u001b[43mpg_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m film_deposition_id\n",
      "Cell \u001b[1;32mIn[41], line 72\u001b[0m, in \u001b[0;36mpg_query\u001b[1;34m(sql, tup)\u001b[0m\n\u001b[0;32m     69\u001b[0m     cur\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     70\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfetched\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'fetched' referenced before assignment"
     ]
>>>>>>> Stashed changes
    }
   ],
   "source": [
    "\n",
    "sql = '''\n",
    "    INSERT INTO FILM_DEPOSITION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (deposition_type, params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING film_deposition_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(coating_process_columns)), tuple(coating_process_values), AsIs(','.join(coating_process_columns)), tuple(coating_process_values))\n",
    "\n",
    "\n",
    "\n",
    "film_deposition_id = pg_query(sql, tup)\n",
    "film_deposition_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Checking and Storing the subprocess recipes (Solution Treatment, Substrate Pretreatment, Post Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.1 SOLUTION TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2 SUBSTRATE PRETREATMENT"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 35,
=======
   "execution_count": 62,
   "id": "83588e66",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'treatment_type': 'chemical_treat',\n",
       "  'process_step': 1,\n",
<<<<<<< Updated upstream
       "  'params': {'environment': 'air',\n",
       "   'iupac_name': 'methanol',\n",
       "   'temperature': 25,\n",
       "   'time': 15}},\n",
       " 1: {'treatment_type': 'uv_ozone',\n",
       "  'process_step': 2,\n",
       "  'params': {'time': 30},\n",
       "  'meta': {'equipment_model': 'Entela T20'}},\n",
       " 2: {'treatment_type': 'sam',\n",
       "  'process_step': 3,\n",
=======
>>>>>>> Stashed changes
       "  'params': {'sam_name': 'OTS-8',\n",
       "   'iupac_name': 'octyltrichlorosilane',\n",
       "   'pubchem_cid': 21354}}}"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 35,
=======
     "execution_count": 62,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrate_pretreat\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 33,
=======
   "execution_count": 75,
   "id": "64d85b06",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueViolation",
<<<<<<< Updated upstream
     "evalue": "duplicate key value violates unique constraint \"substrate_pretreat_step_treatment_type_params_meta_key\"\nDETAIL:  Key (treatment_type, params, meta)=(chemical_treat, {\"time\": 15, \"iupac_name\": \"methanol\", \"environment\": \"air\", \"temperature\": 25}, {}) already exists.\n",
=======
     "evalue": "duplicate key value violates unique constraint \"substrate_pretreat_step_treatment_type_params_meta_key\"\nDETAIL:  Key (treatment_type, params, meta)=(sam, {\"sam_name\": \"OTS-8\", \"iupac_name\": \"octyltrichlorosilane\", \"pubchem_cid\": 21354}, {}) already exists.\n",
>>>>>>> Stashed changes
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
<<<<<<< Updated upstream
      "\u001b[1;32m<ipython-input-33-f56c9b1ce7b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m      '''\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsert_step_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtreatment_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0msubstrate_pretreat_step_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"substrate_pretreat_step_treatment_type_params_meta_key\"\nDETAIL:  Key (treatment_type, params, meta)=(chemical_treat, {\"time\": 15, \"iupac_name\": \"methanol\", \"environment\": \"air\", \"temperature\": 25}, {}) already exists.\n"
=======
      "Cell \u001b[1;32mIn[75], line 35\u001b[0m\n\u001b[0;32m     27\u001b[0m meta \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(substrate_pretreat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m, {}))\n\u001b[0;32m     29\u001b[0m insert_step_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m    INSERT INTO SUBSTRATE_PRETREAT_STEP (treatment_type, params, meta)\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m    VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m    RETURNING substrate_pretreat_step_id\u001b[39m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_step_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreatment_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m substrate_pretreat_step_id \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchone()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m  \u001b[38;5;66;03m# Insert into SUBSTRATE_PRETREAT_ORDER table\u001b[39;00m\n",
      "\u001b[1;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"substrate_pretreat_step_treatment_type_params_meta_key\"\nDETAIL:  Key (treatment_type, params, meta)=(sam, {\"sam_name\": \"OTS-8\", \"iupac_name\": \"octyltrichlorosilane\", \"pubchem_cid\": 21354}, {}) already exists.\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = pg.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "# Generate substrate_pretreat_id and insert records into SUBSTRATE_PRETREAT, SUBSTRATE_PRETREAT_STEP, and SUBSTRATE_PRETREAT_ORDER tables\n",
    "for key, value in substrate_pretreat[0].items():\n",
    "    \n",
    "    \n",
    "       # Insert into SUBSTRATE_PRETREAT table\n",
    "    insert_pretreat_query = '''\n",
    "        INSERT INTO SUBSTRATE_PRETREAT DEFAULT VALUES\n",
    "        RETURNING substrate_pretreat_id\n",
    "    '''\n",
    "    cur.execute(insert_pretreat_query)\n",
    "    substrate_pretreat_id = cur.fetchone()[0]\n",
    "\n",
    "    \n",
    "    # Insert into SUBSTRATE_PRETREAT_STEP table\n",
    "    treatment_type = substrate_pretreat[0].get(\"treatment_type\")\n",
    "    params = json.dumps(substrate_pretreat[0].get(\"params\"))\n",
    "    meta = json.dumps(substrate_pretreat[0].get('meta', {}))\n",
    "\n",
    "    insert_step_query = '''\n",
<<<<<<< Updated upstream
    "         INSERT INTO SUBSTRATE_PRETREAT_STEP (treatment_type, params, meta)\n",
    "         VALUES (%s, %s, %s)\n",
    "         RETURNING substrate_pretreat_step_id\n",
    "\n",
    "     '''\n",
=======
    "        INSERT INTO SUBSTRATE_PRETREAT_STEP (treatment_type, params, meta)\n",
    "        VALUES (%s, %s, %s)\n",
    "        RETURNING substrate_pretreat_step_id\n",
    "\n",
    "    '''\n",
>>>>>>> Stashed changes
    "    cur.execute(insert_step_query, (treatment_type, params, meta))\n",
    "    substrate_pretreat_step_id = cur.fetchone()[0]\n",
    "\n",
    "     # Insert into SUBSTRATE_PRETREAT_ORDER table\n",
    "    process_order = substrate_pretreat[0].get(\"process_step\")\n",
    "    \n",
    "    insert_order_query = '''\n",
    "        INSERT INTO SUBSTRATE_PRETREAT_ORDER (substrate_pretreat_id, process_order, substrate_pretreat_step_id)\n",
    "        VALUES (%s, %s,%s)\n",
    "    '''\n",
    "    cur.execute(insert_order_query, (substrate_pretreat_id, process_order,substrate_pretreat_step_id))\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "invalid integer value \"your_port\" for connection option \"port\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ef693d8f7682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Establish a connection to the PostgreSQL database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your_database\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your_username\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your_password\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your_host\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"your_port\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Create a cursor object to interact with the database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\psycopg2\\__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: invalid integer value \"your_port\" for connection option \"port\"\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.3 POST PROCESSING TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Checking and Storing information to the OFET_PROCESS TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Checking and Storing information to the SAMPLE TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Checking and Storing the measurement information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f5a8b522aac8123589db0e64c73ca2530e0ffae51a117df4f813e361992c41db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
