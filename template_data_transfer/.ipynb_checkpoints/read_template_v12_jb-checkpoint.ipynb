{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "d444d2d1",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "## Python Code to Extract Data From Template and Transfer to PostGRE SQL\n",
    "#### Authors : Aaron Liu, Rahul Venkatesh, Jessica Bonsu, Myeongyeon Lee \n",
    "##### Date Edited : 06-28-2023"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "c386b545",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "to do :\n",
    "* add if statements to code blocks to account for empty metas\n",
    "* fix solvent issue\n",
    "* finish measurement issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
<<<<<<< Updated upstream
=======
   "id": "3f975c78",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "\n",
    "import os\n",
    "from psycopg2.extras import Json\n",
    "from psycopg2.extensions import AsIs\n",
    "import functools\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "# import bibtexparser\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
<<<<<<< Updated upstream
=======
   "id": "d8dc8a25",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Functions To Extract Information from Template\n",
    "\n",
    "# Function to remove rows that have no value (NaN) in the second column\n",
    "def remove_emptyrows(df):\n",
    "    nan_mask = ~df.iloc[:,1].isna() \n",
    "    return df[nan_mask]\n",
    "\n",
    "# Function to convert a sheet into dictionary data type\n",
    "def read_sheet(filepath, sheet_name, ordering=False, usecols=\"A,B,D\", meas=False):\n",
    "\n",
    "    ## NOTE: ADD AN ARGUMENT TO DECIDE WHETHER OR NOT TO BRACKET THE SHEET\n",
    "    ## NOTE : The argument \"ordering\" is used for sheets like solution processing or substrate pretreatmant where the order of the processing step matters\n",
    "    ## NOTE : The argument \"usecols\" is to store information from particular columns in the excel sheet\n",
    "    ## NOTE : The argument \"meas\" is used to \n",
    "    \n",
    "    ## Read Sheet Information\n",
    "    df = pd.read_excel(\n",
    "        filepath,\n",
    "        sheet_name=sheet_name,\n",
    "        usecols=usecols\n",
    "    )\n",
    "    \n",
    "    # Call Function To Remove empty rows\n",
    "    df_ = remove_emptyrows(df)\n",
    "    \n",
    "    # Create an empty dictionary\n",
    "    sheet_dict = dict()\n",
    "\n",
    "    # To account for sheets where processing order is important\n",
    "    if ordering==True:\n",
    "        df_list = split_df(df_) #calls function split_df\n",
    "        for i, df in enumerate(df_list):\n",
    "            sheet_dict[i] = table_to_dict(df) #adds each table to the dictionary\n",
    "    else:\n",
    "        sheet_dict = table_to_dict(df_)\n",
    "    \n",
    "    return sheet_dict #returns a dataframe\n",
    "\n",
    "def split_df(df_):\n",
    "    #For sheets where processing order is important, this function finds tables with '#' in the name of the first column title and turns it into a df\n",
    "    \n",
    "    split_idx_mask = df_.iloc[:,0].str.contains('#') #Find the object splits\n",
    "    w = df_[split_idx_mask].index.values\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for i in range(len(w)-1):\n",
    "        next_df = df_.loc[w[i]+1:w[i+1]-1,:]\n",
    "        df_list.append(next_df)    \n",
    "    \n",
    "    return df_list\n",
    "\n",
    "def table_to_dict(df_):\n",
    "    \n",
    "    main_mask = pd.isna(df_.JSON) # it flags rows that dont have a value for JSON column\n",
    "    step_dict = dict(df_[main_mask].iloc[:,:2].values) # Stores rows that have \"NaN\" for JSON column in df_ as dict\n",
    "\n",
    "    \n",
    "    \n",
    "    for json_field in pd.unique(df_.JSON): #read through unique JSON types (e.g. NaN, meta or data)\n",
    "\n",
    "        if pd.isna(json_field): #ignore fields with JSON type as NaN\n",
    "            continue\n",
    "            \n",
    "        # dictionary to store information with JSON type \"data\"\n",
    "        elif json_field=='data':\n",
    "            data_mask = df_.JSON=='data'\n",
    "            \n",
    "            # lump key:value pairs into a second nested data dict\n",
    "            step_dict['data'] = dict()\n",
    "            \n",
    "            for i, s in df_[data_mask].iterrows():\n",
    "                step_dict['data'][s[s.index[0]]] = s['value':'error_type'].dropna().to_dict()\n",
    "        else:\n",
    "            json_mask = df_.JSON==json_field\n",
    "            step_dict[json_field] = dict(df_[json_mask].iloc[:,:2].values) # creates a new key for JSON types like meta and params and adds its corresponding values to it \n",
    "\n",
    "    return step_dict\n",
    "\n",
    "# f = pd.ExcelFile(fpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "1e7c1e4f",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### Reading and Extracting Data From Sheets in Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
<<<<<<< Updated upstream
=======
   "id": "d86893af",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "#Reading Data From Sheets in Template\n",
    "\n",
    "fpath = r'..\\db_feed\\v6_example.xlsx' #Add path for template file\n",
    "#fpath = r'..\\db_feed\\v6_example_blend.xlsx' #Add path for template file\n",
    "#fpath = r'..\\db_feed\\v6_example_4.xlsx' #Add path for template file\n",
    "\n",
    "#Storing each sheet in the template file as a dictionary\n",
    "exp_info = read_sheet(fpath, 'Data Origin')\n",
    "solution_makeup = read_sheet(fpath, 'Solution Makeup', ordering=True)\n",
    "solution_processing = read_sheet(fpath, 'Solution Treatment', ordering=True)\n",
    "device_fab = read_sheet(fpath, 'Device Fabrication')\n",
    "substrate_pretreat = read_sheet(fpath, 'Substrate Pretreat', ordering=True)\n",
    "coating_process = read_sheet(fpath, 'Coating Process')\n",
    "post_process = read_sheet(fpath, 'Post-Processing', ordering=True)\n",
    "device_meas = read_sheet(fpath, 'Device Measurement', usecols=\"A:G\", ordering=True)\n",
    "other_meas = read_sheet(fpath, 'Other Measurements', usecols=\"A:G\", ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
<<<<<<< Updated upstream
=======
   "id": "07475d43",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'measurement_type': 'uv_vis_film',\n",
       "  'meta': {'equipment_description': 'Cary 60 UV-vis'},\n",
       "  'data': {'A00_A01': {'value': 0.54},\n",
       "   'exciton_bandwidth': {'value': 50, 'unit': 'meV'}}},\n",
       " 1: {'measurement_type': 'giwaxs',\n",
       "  'data': {'100_d_spacing': {'value': 27, 'unit': 'A'}}}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use this code block to check how each sheet has been converted to a dictionary\n",
    "other_meas"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "96973d7e",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### Transferring Information From Template To PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
<<<<<<< Updated upstream
=======
   "id": "5751f36c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres python\n",
    "from psycopg2.extras import Json \n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def nan_to_null(f,\n",
    "        _NULL=AsIs('NULL'),\n",
    "        _Float=pg.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "param_dict = {\n",
    "    \"host\"      : \"127.0.0.1\",\n",
    "    \"database\"  : \"ofetdb_testenv\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = connect(param_dict)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "        # Fetch result\n",
    "        fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return fetched #return query result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
<<<<<<< Updated upstream
=======
   "id": "00d14a5c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import Json\n",
    "\n",
    "def convert_entry(entry_dict):\n",
    "    \n",
    "    #This function reads a dictionary and extracts the column names and values from it\n",
    "    \n",
    "    pg_entry = entry_dict\n",
    "    for key in pg_entry.keys():\n",
    "        if type(pg_entry[key])==dict:\n",
    "            pg_entry[key]=Json(pg_entry[key])\n",
    "    columns = pg_entry.keys()\n",
    "    values = [pg_entry[column] for column in columns]\n",
    "    \n",
    "    return pg_entry, columns, values\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "e441badb",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "###### Doubt 1 : \n",
    "\n",
    "I made a new database. we were not able to add any new records to the old database\n",
    "\n",
    "- might have to manually fix this"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "a1cb47c2",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 1.Checking and Storing Experiment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
<<<<<<< Updated upstream
=======
   "id": "abcb53ca",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation_type': 'literature',\n",
       " 'meta': {'first_name': 'Aaron',\n",
       "  'last_name': 'Liu',\n",
       "  'email': 'aliu319@gatech.edu',\n",
       "  'doi': '10.1038/srep24476 ',\n",
       "  'publication_type': 'journal_article'}}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
<<<<<<< Updated upstream
=======
   "id": "e19bd40d",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['citation_type', 'meta'])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "exp_pg_entry, exp_columns, exp_values = convert_entry(exp_info)\n",
    "\n",
    "#print(type(pg_entry))\n",
    "#print(type(columns))\n",
    "#print(exp_columns)\n",
    "#print(type(values))\n",
    "#print(values)\n",
    "\n",
    "exp_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
<<<<<<< Updated upstream
=======
   "id": "12c0c7cd",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO experiment_info (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (citation_type, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING exp_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(exp_columns)), tuple(exp_values), AsIs(','.join(exp_columns)), tuple(exp_values))\n",
    "\n",
    "\n",
    "\n",
    "exp_id = pg_query(sql, tup)\n",
    "exp_id\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "d4e8c37a",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 2.Checking and Storing Solution Information (Polymer, Solvent, Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
<<<<<<< Updated upstream
=======
   "id": "726d1022",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'entity_type': 'solution', 'concentration': 4},\n",
       " 1: {'entity_type': 'solvent',\n",
       "  'iupac_name': 'toluene',\n",
       "  'pubchem_cid': 1140,\n",
       "  'vol_frac': 1},\n",
       " 2: {'entity_type': 'polymer',\n",
       "  'common_name': 'DPP-DTT',\n",
       "  'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "  'mn': 55,\n",
       "  'mw': 199,\n",
       "  'dispersity': 3.62,\n",
       "  'wt_frac': 1,\n",
       "  'meta': {'supplier': 'Ossila', 'batch_number': 'M0311A2'}}}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
<<<<<<< Updated upstream
=======
   "id": "9acfb071",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<psycopg2._json.Json object at 0x000001816DA9EF80>, <psycopg2._json.Json object at 0x000001816DA9DC00>, <psycopg2._json.Json object at 0x000001816DA9E3B0>]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "pg_entry_solution_makeup, columns_solution_makeup, values_solution_makeup = convert_entry(solution_makeup)\n",
    "\n",
    "print(values_solution_makeup)\n",
    "print(type(values_solution_makeup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
<<<<<<< Updated upstream
=======
   "id": "50185c9d",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_type': 'solution', 'concentration': 4}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solution data\n",
    "\n",
    "solution_data = values_solution_makeup[0].adapted\n",
    "\n",
    "solution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
<<<<<<< Updated upstream
=======
   "id": "fb58406e",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'solvent',\n",
       "  'iupac_name': 'toluene',\n",
       "  'pubchem_cid': 1140,\n",
       "  'vol_frac': 1}]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solvent data - accounting for multiple solvents\n",
    "solvent_data_filtered = [json_obj for json_obj in values_solution_makeup if json_obj.adapted.get(\"entity_type\") == \"solvent\"]\n",
    "\n",
    "# Convert psycopg2._json.Json objects to JSON strings\n",
    "solvent_data = [json_obj.adapted for json_obj in solvent_data_filtered]\n",
    "\n",
    "solvent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
<<<<<<< Updated upstream
=======
   "id": "63880417",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'polymer',\n",
       "  'common_name': 'DPP-DTT',\n",
       "  'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "  'mn': 55,\n",
       "  'mw': 199,\n",
       "  'dispersity': 3.62,\n",
       "  'wt_frac': 1,\n",
       "  'meta': {'supplier': 'Ossila', 'batch_number': 'M0311A2'}}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Polymer data - accounting for multiple polymers\n",
    "polymer_data_filtered = [json_obj for json_obj in values_solution_makeup if json_obj.adapted.get(\"entity_type\") == \"polymer\"]\n",
    "\n",
    "# Convert psycopg2._json.Json objects to JSON strings\n",
    "polymer_data = [json_obj.adapted for json_obj in polymer_data_filtered]\n",
    "\n",
    "polymer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
<<<<<<< Updated upstream
=======
   "id": "af2751ce",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_type': 'solution', 'concentration': 4},\n",
       " [{'entity_type': 'solvent',\n",
       "   'iupac_name': 'toluene',\n",
       "   'pubchem_cid': 1140,\n",
       "   'vol_frac': 1}],\n",
       " [{'entity_type': 'polymer',\n",
       "   'common_name': 'DPP-DTT',\n",
       "   'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "   'mn': 55,\n",
       "   'mw': 199,\n",
       "   'dispersity': 3.62,\n",
       "   'wt_frac': 1,\n",
       "   'meta': {'supplier': 'Ossila', 'batch_number': 'M0311A2'}}]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing Solution Makeup data\n",
    "\n",
    "solution_makeup_data = []\n",
    "solution_makeup_data.append(solution_data)\n",
    "solution_makeup_data.append(solvent_data)\n",
    "solution_makeup_data.append(polymer_data)\n",
    "solution_makeup_data"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "49a78b85",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "##### Inserting into POLYMER, SOLVENT, SOLUTION, SOLUTION_MAKEUP_POLYMER, SOLUTION_MAKEUP_SOLVENT tables"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "85c84953",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "This code should handle multiple solvents each with a vol_frac and multiple polymers each with a wt_frac, and it will check for the existence of a unique combination of concentration, polymer IDs, solvent IDs, wt_fracs, and vol_fracs. If the combination exists, it will assign the existing solution_id in all tables; otherwise, it will create a new solution_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
<<<<<<< Updated upstream
=======
   "id": "506750ff",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "##ORIGINAL CODE FROM RAHUL V12\n",
    "\n",
    "# import json\n",
    "# import psycopg2\n",
    "\n",
    "# # Establish a connection to the database\n",
    "# connection = psycopg2.connect(**param_dict)\n",
    "\n",
    "# # Create a cursor object to execute SQL commands\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "# # Extract solution information\n",
    "# solution_data = solution_makeup_data[0]\n",
    "# concentration = solution_data['concentration']\n",
    "\n",
    "# # Extract solvent information\n",
    "# solvent_data = solution_makeup_data[1]\n",
    "# solvent_ids = []\n",
    "# vol_fracs = []\n",
    "# for solvent in solvent_data:\n",
    "#     pubchem_cid = solvent['pubchem_cid']\n",
    "#     iupac_name = solvent['iupac_name']\n",
    "#     vol_frac = solvent['vol_frac']\n",
    "#     solvent_ids.append((pubchem_cid, iupac_name))\n",
    "#     vol_fracs.append(vol_frac)\n",
    "\n",
    "# # Extract polymer information\n",
    "# polymer_data = solution_makeup_data[2]\n",
    "# polymer_ids = []\n",
    "# wt_fracs = []\n",
    "# for polymer in polymer_data:\n",
    "#     common_name = polymer['common_name']\n",
    "#     iupac_name = polymer['iupac_name']\n",
    "#     mn = polymer['mn']\n",
    "#     mw = polymer['mw']\n",
    "#     dispersity = polymer['dispersity']\n",
    "#     wt_frac = polymer['wt_frac']\n",
    "#     meta = json.dumps(polymer['meta'])\n",
    "#     polymer_ids.append((common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "#     wt_fracs.append(wt_frac)\n",
    "\n",
    "# # Start transaction\n",
    "# with connection:\n",
    "#     with connection.cursor() as cursor:\n",
    "#         try:\n",
    "#             # Check if the unique combination exists\n",
    "#             select_solution_id_sql = '''\n",
    "#                 SELECT sm.solution_id\n",
    "#                 FROM SOLUTION_MAKEUP_SOLVENT sms\n",
    "#                 JOIN SOLUTION_MAKEUP_POLYMER smp ON sms.solution_id = smp.solution_id\n",
    "#                 JOIN SOLVENT s ON sms.solvent_id = s.pubchem_cid\n",
    "#                 JOIN POLYMER p ON smp.polymer_id = p.polymer_id\n",
    "#                 JOIN SOLUTION sm ON sms.solution_id = sm.solution_id\n",
    "#                 WHERE sm.concentration = %s\n",
    "#                 AND (s.pubchem_cid, s.iupac_name) IN %s\n",
    "#                 AND (p.common_name, p.iupac_name, p.mn, p.mw, p.dispersity, p.meta) IN %s\n",
    "#                 GROUP BY sm.solution_id\n",
    "#                 HAVING COUNT(DISTINCT smp.polymer_id) = %s\n",
    "#                 AND COUNT(DISTINCT sms.solvent_id) = %s\n",
    "#                 AND ARRAY_AGG(sms.vol_frac) = %s::double precision[]\n",
    "#                 AND ARRAY_AGG(smp.wt_frac) = %s::double precision[]\n",
    "#             '''\n",
    "\n",
    "#             cursor.execute(select_solution_id_sql, (concentration, tuple(solvent_ids), tuple(polymer_ids), len(polymer_ids), len(solvent_ids), vol_fracs, wt_fracs))\n",
    "#             existing_solution = cursor.fetchone()\n",
    "            \n",
    "#             #Checking if there is existing solution\n",
    "#             if existing_solution:\n",
    "#                 solution_id = existing_solution[0]\n",
    "#             else:\n",
    "#                 # Insert into SOLUTION table\n",
    "#                 insert_solution_sql = '''\n",
    "#                     INSERT INTO SOLUTION (concentration)\n",
    "#                     VALUES (%s)\n",
    "#                     RETURNING solution_id\n",
    "#                 '''\n",
    "#                 cursor.execute(insert_solution_sql, (concentration,))\n",
    "#                 solution_id = cursor.fetchone()[0]\n",
    "\n",
    "#             #Reading Solvent data    \n",
    "#             for solvent_id, vol_frac in zip(solvent_ids, vol_fracs):\n",
    "#                 pubchem_cid, iupac_name = solvent_id\n",
    "                \n",
    "#                 # Check if the solvent exists\n",
    "#                 select_solvent_id_sql = '''\n",
    "#                     SELECT pubchem_cid\n",
    "#                     FROM SOLVENT\n",
    "#                     WHERE iupac_name = %s\n",
    "#                 '''\n",
    "#                 cursor.execute(select_solvent_id_sql, (iupac_name,))\n",
    "#                 existing_solvent = cursor.fetchone()\n",
    "\n",
    "#                 if existing_solvent:\n",
    "#                     solvent_id = existing_solvent[0]\n",
    "#                 else:\n",
    "#                     # Insert into SOLVENT table\n",
    "#                     insert_solvent_sql = '''\n",
    "#                         INSERT INTO SOLVENT (pubchem_cid, iupac_name)\n",
    "#                         VALUES (%s, %s)\n",
    "#                         RETURNING pubchem_cid\n",
    "#                     '''\n",
    "#                     cursor.execute(insert_solvent_sql, (pubchem_cid, iupac_name))\n",
    "#                     solvent_id = cursor.fetchone()[0]\n",
    "                    \n",
    "#                 # Insert or update SOLUTION_MAKEUP_SOLVENT table\n",
    "#                 insert_solution_makeup_solvent_sql = '''\n",
    "#                     INSERT INTO SOLUTION_MAKEUP_SOLVENT (solution_id, solvent_id, vol_frac)\n",
    "#                     VALUES (%s, %s, %s)\n",
    "#                     ON CONFLICT (solution_id, solvent_id, vol_frac) DO UPDATE\n",
    "#                     SET solution_id = SOLUTION_MAKEUP_SOLVENT.solution_id,\n",
    "#                         solvent_id = SOLUTION_MAKEUP_SOLVENT.solvent_id,\n",
    "#                         vol_frac = SOLUTION_MAKEUP_SOLVENT.vol_frac\n",
    "#                 '''\n",
    "#                 cursor.execute(insert_solution_makeup_solvent_sql, (solution_id, solvent_id, vol_frac))\n",
    "\n",
    "\n",
    "#             #Reading the polymer data    \n",
    "#             for polymer_id, wt_frac in zip(polymer_ids, wt_fracs):\n",
    "#                 common_name, iupac_name, mn, mw, dispersity, meta = polymer_id\n",
    "\n",
    "#                 # Check if the polymer exists\n",
    "#                 select_polymer_id_sql = '''\n",
    "#                     SELECT polymer_id\n",
    "#                     FROM POLYMER\n",
    "#                     WHERE common_name = %s\n",
    "#                     AND iupac_name = %s\n",
    "#                     AND mn = %s\n",
    "#                     AND mw = %s\n",
    "#                     AND dispersity = %s\n",
    "#                     AND meta = %s::jsonb\n",
    "#                 '''\n",
    "#                 cursor.execute(select_polymer_id_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "#                 existing_polymer = cursor.fetchone()\n",
    "\n",
    "#                 if existing_polymer:\n",
    "#                     polymer_id = existing_polymer[0]\n",
    "#                 else:\n",
    "#                     # Insert into POLYMER table\n",
    "#                     insert_polymer_sql = '''\n",
    "#                         INSERT INTO POLYMER (common_name, iupac_name, mn, mw, dispersity, meta)\n",
    "#                         VALUES (%s, %s, %s, %s, %s, %s::jsonb)\n",
    "#                         RETURNING polymer_id\n",
    "#                     '''\n",
    "#                     cursor.execute(insert_polymer_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "#                     polymer_id = cursor.fetchone()[0]\n",
    "\n",
    "#                 # Insert or update SOLUTION_MAKEUP_POLYMER table\n",
    "#                 insert_solution_makeup_polymer_sql = '''\n",
    "#                     INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "#                     VALUES (%s, %s, %s)\n",
    "#                     ON CONFLICT (solution_id, polymer_id, wt_frac) DO UPDATE\n",
    "#                     SET solution_id = SOLUTION_MAKEUP_POLYMER.solution_id,\n",
    "#                         polymer_id = SOLUTION_MAKEUP_POLYMER.polymer_id,\n",
    "#                         wt_frac = SOLUTION_MAKEUP_POLYMER.wt_frac\n",
    "#                 '''\n",
    "#                 cursor.execute(insert_solution_makeup_polymer_sql, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "#             connection.commit()\n",
    "\n",
    "#             print(\"Solution makeup saved successfully!\")\n",
    "#             print(solution_id)\n",
    "#         except Exception as e:\n",
    "#             connection.rollback()\n",
    "#             print(\"An error occurred:\", str(e))\n",
    "\n",
    "# # Close the database connection\n",
    "# connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "812dcf46",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### Broke apart above cell into separate, multiple cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
<<<<<<< Updated upstream
=======
   "id": "084463ee",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = connection.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
<<<<<<< Updated upstream
=======
   "id": "2faa2700",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_type': 'solution', 'concentration': 4}\n",
      "concentration:4\n"
     ]
    }
   ],
   "source": [
    "# Extract solution information\n",
    "solution_data = solution_makeup_data[0]\n",
    "print(solution_data)\n",
    "concentration = solution_data['concentration']\n",
    "print(\"concentration:{}\".format(concentration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
<<<<<<< Updated upstream
=======
   "id": "a9f079c8",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solvent_data:[{'entity_type': 'solvent', 'iupac_name': 'toluene', 'pubchem_cid': 1140, 'vol_frac': 1}]\n",
      "solvent_ids:[(1140, 'toluene')]\n",
      "vol_fracs:[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Extract solvent information\n",
    "solvent_data = solution_makeup_data[1]\n",
    "solvent_ids = []\n",
    "vol_fracs = []\n",
    "for solvent in solvent_data:\n",
    "    pubchem_cid = solvent['pubchem_cid']\n",
    "    iupac_name = solvent['iupac_name']\n",
    "    vol_frac = solvent['vol_frac']\n",
    "    solvent_ids.append((pubchem_cid, iupac_name))   \n",
    "    vol_fracs.append(vol_frac)\n",
    "    \n",
    "    \n",
    "print(\"solvent_data:{}\".format(solvent_data))\n",
    "print(\"solvent_ids:{}\".format(solvent_ids))\n",
    "print(\"vol_fracs:{}\".format(vol_fracs))\n",
    "print(len(solvent_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
<<<<<<< Updated upstream
=======
   "id": "cbb905b6",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polymer_data:[{'entity_type': 'polymer', 'common_name': 'DPP-DTT', 'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 'mn': 55, 'mw': 199, 'dispersity': 3.62, 'wt_frac': 1, 'meta': {'supplier': 'Ossila', 'batch_number': 'M0311A2'}}]\n",
      "##################################\n",
      "polymer_ids:[('DPP-DTT', 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 55, 199, 3.62, '{\"supplier\": \"Ossila\", \"batch_number\": \"M0311A2\"}')]\n",
      "##################################\n",
      "wt_fracs:[1]\n"
     ]
    }
   ],
   "source": [
    "# Extract polymer information\n",
    "polymer_data = solution_makeup_data[2]\n",
    "polymer_ids = []\n",
    "wt_fracs = []\n",
    "for polymer in polymer_data:\n",
    "    common_name = polymer['common_name']\n",
    "    iupac_name = polymer['iupac_name']\n",
    "    mn = polymer['mn']\n",
    "    mw = polymer['mw']\n",
    "    dispersity = polymer['dispersity']\n",
    "    wt_frac = polymer['wt_frac']\n",
    "    meta = json.dumps(polymer['meta'])\n",
    "    polymer_ids.append((common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "    wt_fracs.append(wt_frac)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"polymer_data:{}\".format(polymer_data))\n",
    "print('##################################')\n",
    "print(\"polymer_ids:{}\".format(polymer_ids))\n",
    "print('##################################')\n",
    "print(\"wt_fracs:{}\".format(wt_fracs))\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "c19be7d5",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### A sentinel value is a special value that is used to indicate a particular condition or state. In this case, BLANK_SOLUTION_ID is being used as a placeholder value to indicate that there is no valid solution_id available."
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "0f8f50cb",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### unable to break it down further because all under loop. worked with select_solution_id_sql statement separately before adding polymer data section. Checked for existing solution_id before long sql query."
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "2a0f4896",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### ERROR: everything uploading to pgAdmin except polymer, solution_makeup_polymer/sovent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
<<<<<<< Updated upstream
=======
   "id": "8f2a98b9",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution makeup saved successfully!\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Define the sentinel value for a blank solution_id\n",
    "BLANK_SOLUTION_ID = -1\n",
    "        \n",
    "# Start transaction\n",
    "with connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        try:\n",
    "            # Check if there is an existing solution\n",
    "            select_existing_solution_sql = '''\n",
    "                SELECT solution_id\n",
    "                FROM SOLUTION\n",
    "                WHERE concentration = %s\n",
    "            '''\n",
    "            cursor.execute(select_existing_solution_sql, (concentration,))\n",
    "            existing_solution = cursor.fetchone()\n",
    "\n",
    "            if existing_solution:\n",
    "                solution_id = existing_solution[0]\n",
    "            else:\n",
    "                # Perform the join query to find the solution_id\n",
    "                select_solution_id_sql = '''\n",
    "                    SELECT sm.solution_id\n",
    "                    FROM SOLUTION_MAKEUP_SOLVENT sms\n",
    "                    JOIN SOLUTION_MAKEUP_POLYMER smp ON sms.solution_id = smp.solution_id\n",
    "                    JOIN SOLVENT s ON sms.solvent_id = s.pubchem_cid\n",
    "                    JOIN POLYMER p ON smp.polymer_id = p.polymer_id\n",
    "                    JOIN SOLUTION sm ON sms.solution_id = sm.solution_id\n",
    "                    WHERE sm.concentration = %s\n",
    "                    AND (s.pubchem_cid, s.iupac_name) IN %s\n",
    "                    AND (p.common_name, p.iupac_name, p.mn, p.mw, p.dispersity, p.meta) IN %s\n",
    "                    GROUP BY sm.solution_id\n",
    "                    HAVING COUNT(DISTINCT smp.polymer_id) = %s\n",
    "                    AND COUNT(DISTINCT sms.solvent_id) = %s\n",
    "                    AND ARRAY_AGG(sms.vol_frac) = %s::double precision[]\n",
    "                    AND ARRAY_AGG(smp.wt_frac) = %s::double precision[]\n",
    "                '''\n",
    "\n",
    "                cursor.execute(select_solution_id_sql, (concentration, tuple(solvent_ids), tuple(polymer_ids), len(polymer_ids), len(solvent_ids), vol_fracs, wt_fracs))\n",
    "                result = cursor.fetchone()\n",
    "\n",
    "                if result:\n",
    "                    solution_id = result[0]\n",
    "                else:\n",
    "                    # Insert into SOLUTION table\n",
    "                    insert_solution_sql = '''\n",
    "                        INSERT INTO SOLUTION (concentration)\n",
    "                        VALUES (%s)\n",
    "                        RETURNING solution_id\n",
    "                    '''\n",
    "                    cursor.execute(insert_solution_sql, (concentration,))\n",
    "                    solution_id = cursor.fetchone()[0]\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "            print(\"Solution makeup saved successfully!\")\n",
    "            print(solution_id)\n",
    "        except Exception as e:\n",
    "            connection.rollback()\n",
    "            \n",
    "            \n",
    "            # Reading the polymer data    \n",
    "            for polymer_id, wt_frac in zip(polymer_ids, wt_fracs):\n",
    "                common_name, iupac_name, mn, mw, dispersity, meta = polymer_id\n",
    "\n",
    "                # Check if the polymer exists\n",
    "                select_polymer_id_sql = '''\n",
    "                    SELECT polymer_id\n",
    "                    FROM POLYMER\n",
    "                    WHERE common_name = %s\n",
    "                    AND iupac_name = %s\n",
    "                    AND mn = %s\n",
    "                    AND mw = %s\n",
    "                    AND dispersity = %s\n",
    "                    AND meta = %s::jsonb\n",
    "                '''\n",
    "                cursor.execute(select_polymer_id_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                existing_polymer = cursor.fetchone()\n",
    "\n",
    "                if existing_polymer:\n",
    "                    polymer_id = existing_polymer[0]\n",
    "                else:\n",
    "                    # Insert into POLYMER table\n",
    "                    insert_polymer_sql = '''\n",
    "                        INSERT INTO POLYMER (common_name, iupac_name, mn, mw, dispersity, meta)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s::jsonb)\n",
    "                        RETURNING polymer_id\n",
    "                    '''\n",
    "                    cursor.execute(insert_polymer_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                    polymer_id = cursor.fetchone()[0]\n",
    "\n",
    "                # Insert or update SOLUTION_MAKEUP_POLYMER table\n",
    "                insert_solution_makeup_polymer_sql = '''\n",
    "                    INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT (solution_id, polymer_id, wt_frac) DO UPDATE\n",
    "                    SET solution_id = SOLUTION_MAKEUP_POLYMER.solution_id,\n",
    "                        polymer_id = SOLUTION_MAKEUP_POLYMER.polymer_id,\n",
    "                        wt_frac = SOLUTION_MAKEUP_POLYMER.wt_frac\n",
    "                '''\n",
    "                cursor.execute(insert_solution_makeup_polymer_sql, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "            #Reading the polymer data    \n",
    "            for polymer_id, wt_frac in zip(polymer_ids, wt_fracs):\n",
    "                common_name, iupac_name, mn, mw, dispersity, meta = polymer_id\n",
    "\n",
    "                # Check if the polymer exists\n",
    "                select_polymer_id_sql = '''\n",
    "                    SELECT polymer_id\n",
    "                    FROM POLYMER\n",
    "                    WHERE common_name = %s\n",
    "                    AND iupac_name = %s\n",
    "                    AND mn = %s\n",
    "                    AND mw = %s\n",
    "                    AND dispersity = %s\n",
    "                    AND meta = %s::jsonb\n",
    "                '''\n",
    "                cursor.execute(select_polymer_id_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                existing_polymer = cursor.fetchone()\n",
    "\n",
    "                if existing_polymer:\n",
    "                    polymer_id = existing_polymer[0]\n",
    "                else:\n",
    "                    # Insert into POLYMER table\n",
    "                    insert_polymer_sql = '''\n",
    "                        INSERT INTO POLYMER (common_name, iupac_name, mn, mw, dispersity, meta)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s::jsonb)\n",
    "                        RETURNING polymer_id\n",
    "                    '''\n",
    "                    cursor.execute(insert_polymer_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                    polymer_id = cursor.fetchone()[0]\n",
    "\n",
    "                # Insert or update SOLUTION_MAKEUP_POLYMER table\n",
    "                insert_solution_makeup_polymer_sql = '''\n",
    "                    INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT (solution_id, polymer_id, wt_frac) DO UPDATE\n",
    "                    SET solution_id = SOLUTION_MAKEUP_POLYMER.solution_id,\n",
    "                        polymer_id = SOLUTION_MAKEUP_POLYMER.polymer_id,\n",
    "                        wt_frac = SOLUTION_MAKEUP_POLYMER.wt_frac\n",
    "                '''\n",
    "                cursor.execute(insert_solution_makeup_polymer_sql, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "            print(\"Solution makeup saved successfully!\")\n",
    "            print(solution_id)\n",
    "        except Exception as e:\n",
    "            connection.rollback()\n",
    "            print(\"An error occurred:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
<<<<<<< Updated upstream
=======
   "id": "8c69e8e1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##INSERT FOR PGADMIN QUERY, printing out blanks\n",
    "# SELECT sm.solution_id\n",
    "# FROM SOLUTION_MAKEUP_SOLVENT sms\n",
    "# JOIN SOLUTION_MAKEUP_POLYMER smp ON sms.solution_id = smp.solution_id\n",
    "# JOIN SOLVENT s ON sms.solvent_id = s.pubchem_cid\n",
    "# JOIN POLYMER p ON smp.polymer_id = p.polymer_id\n",
    "# JOIN SOLUTION sm ON sms.solution_id = sm.solution_id\n",
    "# WHERE sm.concentration = 10\n",
    "# AND (s.pubchem_cid, s.iupac_name) IN ((7239, '1,2-dichlorobenzene') )\n",
    "# AND (p.common_name, p.iupac_name, p.mn, p.mw, p.dispersity, p.meta) IN (('DPP-DTT', 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 55, 199, 3.62, '{\"supplier\": \"Osilla\", \"batch_number\": \"M0311A2\"}'), ('PS', 'poly(styrene)', 2.18, 2.2, 1.01, '{\"supplier\": \"Sigma\", \"batch_number\": \"S1234\"}'))\n",
    "# GROUP BY sm.solution_id\n",
    "# HAVING COUNT(DISTINCT smp.polymer_id) = 2\n",
    "# AND COUNT(DISTINCT sms.solvent_id) = 1\n",
    "# AND ARRAY_AGG(sms.vol_frac) = ARRAY[1]::double precision[]\n",
    "# AND ARRAY_AGG(smp.wt_frac) = ARRAY[0.6, 0.4]::double precision[];"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "df04f383",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 3. Checking and Storing Device Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
<<<<<<< Updated upstream
=======
   "id": "6e883567",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'electrode_configuration': 'BGTC',\n",
       "  'channel_length': 80,\n",
       "  'channel_width': 1500,\n",
       "  'gate_material': 'n-doped Si',\n",
       "  'dielectric_1_material': 'SiO2',\n",
       "  'dielectric_1_thickness': 350},\n",
       " 'meta': {'adhesion_layer': 'Cr', 'electrode_material': 'Au'}}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
<<<<<<< Updated upstream
=======
   "id": "727643b4",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n",
      "dict_keys(['params', 'meta'])\n",
      "<class 'list'>\n",
      "[<psycopg2._json.Json object at 0x000001816DD39210>, <psycopg2._json.Json object at 0x000001816DD389D0>]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "device_fab_pg_entry, device_fab_columns, device_fab_values = convert_entry(device_fab)\n",
    "\n",
    "#print(type(device_fab_pg_entry))\n",
    "print(type(device_fab_columns))\n",
    "print(device_fab_columns)\n",
    "print(type(device_fab_values))\n",
    "print(device_fab_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
<<<<<<< Updated upstream
=======
   "id": "dbe839af",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#If meta information is missing\n",
    "device_fab_columns_list = list(device_fab_columns)  # Convert dict_keys to a list\n",
    "\n",
    "if 'meta' not in device_fab_columns_list:\n",
    "    device_fab_columns_list.append('meta')\n",
    "    device_fab_values.append({})\n",
    "    \n",
    "device_fab_values = [json.dumps(value) if isinstance(value, dict) else value for value in device_fab_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
<<<<<<< Updated upstream
=======
   "id": "8191848a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO DEVICE_FABRICATION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING device_fab_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(device_fab_columns_list)), tuple(device_fab_values), AsIs(','.join(device_fab_columns_list)), tuple(device_fab_values))\n",
    "\n",
    "\n",
    "\n",
    "device_fab_id = pg_query(sql, tup)\n",
    "device_fab_id"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "ab03c69a",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 4. Checking and Storing Film Deposition Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
<<<<<<< Updated upstream
=======
   "id": "28d71486",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n",
      "dict_keys(['deposition_type', 'params'])\n",
      "<class 'list'>\n",
      "['spin', <psycopg2._json.Json object at 0x000001816DD38370>]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "coating_process_pg_entry, coating_process_columns, coating_process_values = convert_entry(coating_process)\n",
    "\n",
    "#print(type(coating_process_pg_entry))\n",
    "print(type(coating_process_columns))\n",
    "print(coating_process_columns)\n",
    "print(type(coating_process_values))\n",
    "print(coating_process_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
<<<<<<< Updated upstream
=======
   "id": "f88f8566",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#If meta information is missing\n",
    "coating_process_columns_list = list(coating_process_columns)  # Convert dict_keys to a list\n",
    "\n",
    "if 'meta' not in coating_process_columns_list:\n",
    "    coating_process_columns_list.append('meta')\n",
    "    coating_process_values.append({})\n",
    "    \n",
    "coating_process_values = [json.dumps(value) if isinstance(value, dict) else value for value in coating_process_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
<<<<<<< Updated upstream
=======
   "id": "2f25efde",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sql = '''\n",
    "    INSERT INTO FILM_DEPOSITION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (deposition_type, params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING film_deposition_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(coating_process_columns_list)), tuple(coating_process_values), AsIs(','.join(coating_process_columns_list)), tuple(coating_process_values))\n",
    "\n",
    "\n",
    "\n",
    "film_deposition_id = pg_query(sql, tup)\n",
    "film_deposition_id"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "30bd12fe",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 5. Checking and Storing the subprocess recipes (Solution Treatment, Substrate Pretreatment, Post Process)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "acd18750",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "###### 5.1 SOLUTION TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
<<<<<<< Updated upstream
=======
   "id": "da64cb6b",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'treatment_type': 'mixing',\n",
       "  'process_step': 1,\n",
       "  'params': {'mixing_speed': 250, 'temperature': 60, 'time': 1}},\n",
       " 1: {'treatment_type': 'poor_solvent',\n",
       "  'process_step': 2,\n",
       "  'params': {'environment': 'air',\n",
       "   'iupac_name': 'acetone',\n",
       "   'pubchem_cid': 180,\n",
       "   'vol_frac_added': 0.05}}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
<<<<<<< Updated upstream
=======
   "id": "8b6f9adb",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution treatment saved successfully!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Function to insert data into SOLUTION_TREATMENT_STEP table\n",
    "def insert_into_solution_treatment_step(cur, treatment_type, params, meta):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"SELECT solution_treatment_step_id FROM SOLUTION_TREATMENT_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "        (treatment_type, params, meta)\n",
    "    )\n",
    "    existing_id = cur.fetchone()\n",
    "\n",
    "    if existing_id:\n",
    "        solution_treatment_step_id = existing_id[0]\n",
    "    else:\n",
    "        # Insert data into SOLUTION_TREATMENT_STEP table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO SOLUTION_TREATMENT_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING solution_treatment_step_id\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        solution_treatment_step_id = cur.fetchone()[0]\n",
    "\n",
    "    return solution_treatment_step_id\n",
    "\n",
    "# Function to insert data into SOLUTION_TREATMENT_ORDER table\n",
    "def insert_into_solution_treatment_order(cur, solution_treatment_id, process_order, solution_treatment_step_id):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT solution_treatment_id\n",
    "        FROM SOLUTION_TREATMENT_ORDER\n",
    "        WHERE solution_treatment_id = %s\n",
    "        AND process_order = %s\n",
    "        AND solution_treatment_step_id = %s\n",
    "        \"\"\",\n",
    "        (solution_treatment_id, process_order, solution_treatment_step_id)\n",
    "    )\n",
    "    existing_combination = cur.fetchone()\n",
    "\n",
    "    if not existing_combination:\n",
    "        # Insert new record into SOLUTION_TREATMENT_ORDER table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO SOLUTION_TREATMENT_ORDER (solution_treatment_id, process_order, solution_treatment_step_id) VALUES (%s, %s, %s)\",\n",
    "            (solution_treatment_id, process_order, solution_treatment_step_id)\n",
    "        )\n",
    "\n",
    "    return solution_treatment_id\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "solution_treatment_id = None\n",
    "\n",
    "for treatment in solution_processing.values():\n",
    "    # Convert params and meta to JSON format\n",
    "    params_json = json.dumps(treatment.get('params', {}))\n",
    "    meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "    # Insert data into SOLUTION_TREATMENT_STEP table\n",
    "    solution_treatment_step_id = insert_into_solution_treatment_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "    if solution_treatment_id is None:\n",
    "        # Check if the record already exists in SOLUTION_TREATMENT table\n",
    "        cur.execute(\n",
    "            \"SELECT solution_treatment_id FROM SOLUTION_TREATMENT WHERE solution_treatment_id IN (SELECT solution_treatment_id FROM SOLUTION_TREATMENT_ORDER WHERE solution_treatment_step_id = %s)\",\n",
    "            (solution_treatment_step_id,)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            solution_treatment_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into SOLUTION_TREATMENT table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SOLUTION_TREATMENT (solution_treatment_id) VALUES (DEFAULT) RETURNING solution_treatment_id\"\n",
    "            )\n",
    "            solution_treatment_id = cur.fetchone()[0]\n",
    "\n",
    "    # Insert data into SOLUTION_TREATMENT_ORDER table\n",
    "    solution_treatment_id = insert_into_solution_treatment_order(cur, solution_treatment_id, treatment['process_step'], solution_treatment_step_id)\n",
    "\n",
    "# Commit the changes to the database\n",
    "print(\"Solution treatment saved successfully!\")\n",
    "print(solution_treatment_id)\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "cd870de5",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "###### 5.2 SUBSTRATE PRETREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
<<<<<<< Updated upstream
=======
   "id": "9e561105",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'treatment_type': 'chemical_treat',\n",
       "  'process_step': 1,\n",
       "  'params': {'environment': 'air',\n",
       "   'iupac_name': 'methanol',\n",
       "   'temperature': 25,\n",
       "   'time': 15},\n",
       "  'meta': {'description': 'sonication'}},\n",
       " 1: {'treatment_type': 'uv_ozone',\n",
       "  'process_step': 2,\n",
       "  'params': {'time': 30},\n",
       "  'meta': {'equipment_model': 'Entela T20'}},\n",
       " 2: {'treatment_type': 'sam',\n",
       "  'process_step': 3,\n",
       "  'params': {'sam_name': 'OTS-8',\n",
       "   'iupac_name': 'octyltrichlorosilane',\n",
       "   'pubchem_cid': 21354}}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrate_pretreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
<<<<<<< Updated upstream
=======
   "id": "a177d87c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substrate pretreatment saved successfully!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Function to insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "def insert_into_substrate_pretreat_step(cur, treatment_type, params, meta):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"SELECT substrate_pretreat_step_id FROM SUBSTRATE_PRETREAT_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "        (treatment_type, params, meta)\n",
    "    )\n",
    "    existing_id = cur.fetchone()\n",
    "\n",
    "    if existing_id:\n",
    "        substrate_pretreat_step_id = existing_id[0]\n",
    "    else:\n",
    "        # Insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO SUBSTRATE_PRETREAT_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING substrate_pretreat_step_id\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        substrate_pretreat_step_id = cur.fetchone()[0]\n",
    "\n",
    "    return substrate_pretreat_step_id\n",
    "\n",
    "# Function to insert data into SUBSTRATE_PRETREAT_ORDER table\n",
    "def insert_into_substrate_pretreat_order(cur, substrate_pretreat_id, process_order, substrate_pretreat_step_id):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT substrate_pretreat_id\n",
    "        FROM SUBSTRATE_PRETREAT_ORDER\n",
    "        WHERE substrate_pretreat_id = %s\n",
    "        AND process_order = %s\n",
    "        AND substrate_pretreat_step_id = %s\n",
    "        \"\"\",\n",
    "        (substrate_pretreat_id, process_order, substrate_pretreat_step_id)\n",
    "    )\n",
    "    existing_combination = cur.fetchone()\n",
    "\n",
    "    if not existing_combination:\n",
    "        # Insert new record into SUBSTRATE_PRETREAT_ORDER table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO SUBSTRATE_PRETREAT_ORDER (substrate_pretreat_id, process_order, substrate_pretreat_step_id) VALUES (%s, %s, %s)\",\n",
    "            (substrate_pretreat_id, process_order, substrate_pretreat_step_id)\n",
    "        )\n",
    "\n",
    "    return substrate_pretreat_id\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "substrate_pretreat_id = None\n",
    "\n",
    "for treatment in substrate_pretreat.values():\n",
    "    # Convert params and meta to JSON format\n",
    "    params_json = json.dumps(treatment.get('params', {}))\n",
    "    meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "    # Insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "    substrate_pretreat_step_id = insert_into_substrate_pretreat_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "    if substrate_pretreat_id is None:\n",
    "        # Check if the record already exists in SUBSTRATE_PRETREAT table\n",
    "        cur.execute(\n",
    "            \"SELECT substrate_pretreat_id FROM SUBSTRATE_PRETREAT WHERE substrate_pretreat_id IN (SELECT substrate_pretreat_id FROM SUBSTRATE_PRETREAT_ORDER WHERE substrate_pretreat_step_id = %s)\",\n",
    "            (substrate_pretreat_step_id,)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            substrate_pretreat_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into SUBSTRATE_PRETREAT table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SUBSTRATE_PRETREAT (substrate_pretreat_id) VALUES (DEFAULT) RETURNING substrate_pretreat_id\"\n",
    "            )\n",
    "            substrate_pretreat_id = cur.fetchone()[0]\n",
    "\n",
    "    # Insert data into SUBSTRATE_PRETREAT_ORDER table\n",
    "    substrate_pretreat_id = insert_into_substrate_pretreat_order(cur, substrate_pretreat_id, treatment['process_step'], substrate_pretreat_step_id)\n",
    "\n",
    "# Commit the changes to the database\n",
    "print(\"Substrate pretreatment saved successfully!\")\n",
    "print(substrate_pretreat_id)\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "6415e7cd",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "###### 5.3 POST PROCESSING TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
<<<<<<< Updated upstream
=======
   "id": "ac471455",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'treatment_type': 'annealing',\n",
       "  'process_step': 1,\n",
       "  'params': {'environment': 'air', 'temperature': 56, 'time': 0.16}}}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
<<<<<<< Updated upstream
=======
   "id": "f84c2cfa",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Process treatment saved successfully!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Function to insert data into POSTPROCESS_STEP table\n",
    "def insert_into_postprocess_step(cur, treatment_type, params, meta):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"SELECT postprocess_step_id FROM POSTPROCESS_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "        (treatment_type, params, meta)\n",
    "    )\n",
    "    existing_id = cur.fetchone()\n",
    "\n",
    "    if existing_id:\n",
    "        postprocess_step_id = existing_id[0]\n",
    "    else:\n",
    "        # Insert data into POSTPROCESS_STEP table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO POSTPROCESS_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING postprocess_step_id\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        postprocess_step_id = cur.fetchone()[0]\n",
    "\n",
    "    return postprocess_step_id\n",
    "\n",
    "# Function to insert data into POSTPROCESS_ORDER table\n",
    "def insert_into_postprocess_order(cur, postprocess_id, process_order, postprocess_step_id):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT postprocess_id\n",
    "        FROM POSTPROCESS_ORDER\n",
    "        WHERE postprocess_id = %s\n",
    "        AND process_order = %s\n",
    "        AND postprocess_step_id = %s\n",
    "        \"\"\",\n",
    "        (postprocess_id, process_order, postprocess_step_id)\n",
    "    )\n",
    "    existing_combination = cur.fetchone()\n",
    "\n",
    "    if not existing_combination:\n",
    "        # Insert new record into POSTPROCESS_ORDER table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO POSTPROCESS_ORDER (postprocess_id, process_order, postprocess_step_id) VALUES (%s, %s, %s)\",\n",
    "            (postprocess_id, process_order, postprocess_step_id)\n",
    "        )\n",
    "\n",
    "    return postprocess_id\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "postprocess_id = None\n",
    "\n",
    "for treatment in post_process.values():\n",
    "    # Convert params and meta to JSON format\n",
    "    params_json = json.dumps(treatment.get('params', {}))\n",
    "    meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "    # Insert data into POSTPROCESS_STEP table\n",
    "    postprocess_step_id = insert_into_postprocess_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "    if postprocess_id is None:\n",
    "        # Check if the record already exists in POSTPROCESS table\n",
    "        cur.execute(\n",
    "            \"SELECT postprocess_id FROM POSTPROCESS WHERE postprocess_id IN (SELECT postprocess_id FROM POSTPROCESS_ORDER WHERE postprocess_step_id = %s)\",\n",
    "            (postprocess_step_id,)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            postprocess_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into POSTPROCESS table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO POSTPROCESS (postprocess_id) VALUES (DEFAULT) RETURNING postprocess_id\"\n",
    "            )\n",
    "            postprocess_id = cur.fetchone()[0]\n",
    "\n",
    "    # Insert data into POSTPROCESS_ORDER table\n",
    "    postprocess_id = insert_into_postprocess_order(cur, postprocess_id, treatment['process_step'], postprocess_step_id)\n",
    "\n",
    "# Commit the changes to the database\n",
    "print(\"Post Process treatment saved successfully!\")\n",
    "print(postprocess_id)\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "1fa1c4e3",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 6. Checking and Storing information to the OFET_PROCESS TABLE and generating process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
<<<<<<< Updated upstream
=======
   "id": "cd86dc21",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution_id is : 1\n",
      "device_fab_id is : 4\n",
      "solution_treatment_id is : 2\n",
      "substrate_pretreat_id is : 2\n",
      "film_deposition_id is : 4\n",
      "postprocess_id is : 2\n"
     ]
    }
   ],
   "source": [
    "#printing the id's of attributes in OFET_PROCESS\n",
    "print(\"solution_id is : {}\".format(solution_id))\n",
    "print(\"device_fab_id is : {}\".format(device_fab_id))\n",
    "print(\"solution_treatment_id is : {}\".format(solution_treatment_id))\n",
    "print(\"substrate_pretreat_id is : {}\".format(substrate_pretreat_id))\n",
    "print(\"film_deposition_id is : {}\".format(film_deposition_id))\n",
    "print(\"postprocess_id is : {}\".format(postprocess_id))\n",
    "\n",
    "ofet_process_columns = ['solution_id','solution_treatment_id','device_fab_id','substrate_pretreat_id','film_deposition_id','postprocess_id']\n",
    "ofet_process_values = [solution_id,solution_treatment_id,device_fab_id,substrate_pretreat_id,film_deposition_id,postprocess_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
<<<<<<< Updated upstream
=======
   "id": "a39bdfb1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO ofet_process (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (solution_id, solution_treatment_id, device_fab_id, substrate_pretreat_id, film_deposition_id, postprocess_id) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING process_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(ofet_process_columns)), tuple(ofet_process_values), AsIs(','.join(ofet_process_columns)), tuple(ofet_process_values))\n",
    "\n",
    "process_id = pg_query(sql, tup)\n",
    "process_id\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "cca7efe5",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 7. Checking and Storing information to the SAMPLE TABLE and generating sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
<<<<<<< Updated upstream
=======
   "id": "830defa3",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_id is : 4\n",
      "process_id is : 4\n"
     ]
    }
   ],
   "source": [
    "#printing the id's of attributes in SAMPLE\n",
    "print(\"exp_id is : {}\".format(exp_id))\n",
    "print(\"process_id is : {}\".format(process_id))\n",
    "\n",
    "\n",
    "sample_columns = ['exp_id','process_id']\n",
    "sample_values = [exp_id,process_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
<<<<<<< Updated upstream
=======
   "id": "81a14dbe",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO sample (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (exp_id, process_id) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING sample_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(sample_columns)), tuple(sample_values), AsIs(','.join(sample_columns)), tuple(sample_values))\n",
    "\n",
    "sample_id = pg_query(sql, tup)\n",
    "sample_id"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "6c7c9dc1",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "### 8. Checking and Storing the measurement information "
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "407afdf2",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### 8.1 Storing Device Measurement Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
<<<<<<< Updated upstream
=======
   "id": "4d060210",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'measurement_type': 'transfer_curve',\n",
       "  'data': {'hole_mobility': {'value': 0.000202,\n",
       "    'unit': 'cm2/V-s',\n",
       "    'replicates': 12,\n",
       "    'error': 6e-05,\n",
       "    'error_type': 'ci_95'},\n",
       "   'hole_threshold_voltage': {'value': 2.5,\n",
       "    'unit': 'V',\n",
       "    'error': 0.1,\n",
       "    'error_type': 'ci_95'}},\n",
       "  'meta': {'mobility_regime': 'linear',\n",
       "   'environment': 'air',\n",
       "   'Vds': -3,\n",
       "   'equipment_description': 'Agilent 4155C'}}}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
<<<<<<< Updated upstream
=======
   "id": "d7f34a34",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['measurement_type', 'data', 'meta'])\n",
      "['transfer_curve', <psycopg2._json.Json object at 0x000001816DD89900>, <psycopg2._json.Json object at 0x000001816DD89AB0>]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "device_meas_pg_entry, device_meas_columns, device_meas_values = convert_entry(device_meas[0])\n",
    "\n",
    "#print(type(coating_process_pg_entry))\n",
    "#print(type(coating_process_columns))\n",
    "print(device_meas_columns)\n",
    "#print(type(coating_process_values))\n",
    "print(device_meas_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
<<<<<<< Updated upstream
=======
   "id": "3d53e397",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device_meas_columns_list = list(device_meas_columns)  # Convert dict_keys to a list\n",
    "device_meas_columns_list.insert(0, 'sample_id')\n",
    "device_meas_values.insert(0, sample_id)\n",
    "\n",
    "# print(device_meas_columns_list)\n",
    "# print(device_meas_values)\n",
    "\n",
    "\n",
    "#If meta information is missing\n",
    "if 'meta' not in device_meas_columns_list:\n",
    "    device_meas_columns_list.append('meta')\n",
    "    device_meas_values.append({})\n",
    "\n",
    "\n",
    "\n",
    "device_meas_values = [json.dumps(value) if isinstance(value, dict) else value for value in device_meas_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
<<<<<<< Updated upstream
=======
   "id": "159fc9a5",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO measurement (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (sample_id,measurement_type,data,meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING measurement_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(device_meas_columns_list)), tuple(device_meas_values), AsIs(','.join(device_meas_columns_list)), tuple(device_meas_values))\n",
    "\n",
    "measurement_id = pg_query(sql, tup)\n",
    "measurement_id"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "c8c08b0e",
>>>>>>> Stashed changes
   "metadata": {},
   "source": [
    "#### 8.1 Storing Other Measurement Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
<<<<<<< Updated upstream
=======
   "id": "adcd8aff",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'measurement_type': 'uv_vis_film',\n",
       "  'meta': {'equipment_description': 'Cary 60 UV-vis'},\n",
       "  'data': {'A00_A01': {'value': 0.54},\n",
       "   'exciton_bandwidth': {'value': 50, 'unit': 'meV'}}},\n",
       " 1: {'measurement_type': 'giwaxs',\n",
       "  'data': {'100_d_spacing': {'value': 27, 'unit': 'A'}}}}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
<<<<<<< Updated upstream
=======
   "id": "b38516a7",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n",
      "11\n",
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for items in other_meas:\n",
    "    other_meas_pg_entry, other_meas_columns, other_meas_values = convert_entry(other_meas[items])\n",
    "\n",
    "    other_meas_columns_list = list(other_meas_columns)  # Convert dict_keys to a list\n",
    "    other_meas_columns_list.insert(0, 'sample_id')\n",
    "    other_meas_values.insert(0, sample_id)\n",
    "\n",
    "    #If meta information is missing\n",
    "    if 'meta' not in other_meas_columns_list:\n",
    "        other_meas_columns_list.append('meta')\n",
    "        other_meas_values.append({})\n",
    "\n",
    "\n",
    "\n",
    "    other_meas_values = [json.dumps(value) if isinstance(value, dict) else value for value in other_meas_values]\n",
    "    \n",
    "    sql = '''\n",
    "    INSERT INTO measurement (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (sample_id,measurement_type,data,meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING measurement_id\n",
    "    \n",
    "    '''\n",
    "    tup = (AsIs(','.join(other_meas_columns_list)), tuple(other_meas_values), AsIs(','.join(other_meas_columns_list)), tuple(other_meas_values))\n",
    "\n",
    "    measurement_id = pg_query(sql, tup)\n",
    "    print(measurement_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "id": "bfe9483f",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "id": "2083284a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< Updated upstream
   "display_name": "Python 3",
=======
   "display_name": "Python 3 (ipykernel)",
>>>>>>> Stashed changes
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.7.3"
=======
   "version": "3.10.9"
>>>>>>> Stashed changes
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f5a8b522aac8123589db0e64c73ca2530e0ffae51a117df4f813e361992c41db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
